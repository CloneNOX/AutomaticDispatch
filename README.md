# AutomaticDispatch
本分支为基于PaddleNLP接口的自动派单系统。

### 1	历史工作

#### 1.1	基于fasttext的文本分类

最初的派单项目是使用fasttext实现的文本分类模型实现的一级文本分类任务。在这个任务中，没有层级分类的概念，即各标签之间没有从属关系。

Fasttext的思想是：将工单文本切分成单个字的序列，例如：【我爱中国】切分成[我，爱，中，国]。模型训练一个词嵌入层，对输入的文本，切分成**字序列**后通入模型获取句子的**词向量序列**。分类过程：对词向量序列去平均，作为文本的特征向量，经过线性层映射到最后的类别分类向量，实现多分类。

在最初的分类需求中，上家开发人员通过面向数据的编程，通过关键词检测等手段，处理一部分特征明显的工单，随后通过fasttext处理剩余的工单，在当时满足了客户的需求。

#### 1.2	基于fasttext的层级文本分类

我们接手派单项目之后，通过分析上家的源码，发现存在几个可优化点：

1. 原方法从字的尺度对文本进行编码及特征提取，忽略了中文存在词尺度的上下文信息。举个例子：【我爱中国】切分成[我，爱，中，国]，相当于将【I love china】切分成[I, l, o, v, e, c, h, i, n, a]，随后进行fasttext文本特征提取，这造成了上下文信息丢失。
2. 原方法没有适配层级分类，新的需求要求对工单进行层级分类，不同层级之间具有依赖性，原方法显然不适用。

在初步尝试阶段，根据上述分析，我们引入了Jieba分词库（一个应用广泛的中文分词库）以解决词尺度的上下文信息丢失。我们针对3个层级各训练了一个fasttext分类器，以解决层级分类的标签分层问题。

在尝试中，我们发现，对非层级分类的场景中，引入Jieba分词的fasttext相较于纯fasttext有明显的性能提升。但是在层级分类场景中，仍未能很好地解决标签依赖的问题。例如：真实标签是**荔湾区政府-荔湾区公安分局-桥中街道派出所**，是一个三级分类标签，在三个模型中的分类结果可能是：**荔湾区政府-桥中街道-桥中街道派出所**。这是二级标签与三级标签不匹配的问题。

### 2	现在的算法

通过调研，我们选择了[基于Paddle的Encoder——ERNIE的层级分类模型][1]（简称Hierarchical），作文分类模型，相较于之前的工作，改善有：

1. Encoder类词嵌入模型特征提取能力比fasttext更强，Encoder拥有自带的预训练分词器，相较于基于统计的Jieba分词器会更适配多变的语境。同时预训练模型拥有大量语料库作为底模支撑，在finetune的过程中相对更不容易发生过拟合。
2. Hierarchical在设置标签的时候，引入了不同层级之间依赖关系，具体而言，是让三级标签的标签文本中包含前两级标签的文本，使用特定的分隔符分隔。

Hierarchical的分类机制：使用ERNIE对输入文本进行编码，提取出文本的特征向量；整合多级标签，进行编码得到标签特征向量。通过计算文本特征向量与标签特征向量的余弦相似度，获得文本属于该标签的置信度。在这一步中，因为低级标签包含高级标签的文本，因此可以实现模型提取层级标签之间的依赖关系信息。

现有方法的弊端：

1. PaddlePaddle框架相较于PyTorch更难使用，如果使用现成开源代码开发，需要配置Paddle的环境，是相对麻烦的。可以用Docker解决这一个问题。
2. 我们目前还没有完全拆解分析ERNIE模型的源码及模型结构，暂时不能实现移植到Pytorch上用bert-base-chinese实现相似的功能。

### 3	API实现

我们使用了Flask轻量化Web框架实现了简单的Web API接口化。将模型导出为静态图，实现计算结果后处理，并部署到客户的服务器上，告知客户访问服务的IP和端口号即可。

模型静态图的导出使用Onnx作为导出规格，实现了在无GPU环境的BERT模型部署。在调用频率最高的一次测试中，客户一天调用了1.4万次接口，目前仍未收到客户对于处理速度的投诉。

### 4	总体流程

1. 获取、清洗、准备训练数据
2. 训练分类模型，评估性能，优化改进
3. 根据部署环境，导出模型的静态计算图
4. 准备部署环境的相关组件
5. 在客户机器上部署、试运行
6. 收集客户使用过程的历史数据，再评估优化模型

[1]:https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/text_classification/hierarchical#readme

