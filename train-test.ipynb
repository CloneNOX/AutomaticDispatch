{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import os\n",
    "import json\n",
    "from utils import fixText, resetLabelLv2, resetLabelLv3\n",
    "\n",
    "TEMP_DIR = './tmp/'\n",
    "\n",
    "def getConfig():\n",
    "    config = {}\n",
    "    with open('./config.json', 'r') as f:\n",
    "        s = f.read()\n",
    "        config = json.loads(s)\n",
    "    return config\n",
    "\n",
    "# 读入数据集的json文件，处理成fasttext接口使用的\"文本__label__标签\"形式，以txt文件存储\n",
    "def readDataSet(path):\n",
    "    with open(path, 'r') as f:\n",
    "        s = f.read()\n",
    "        data_set = json.loads(s)\n",
    "    set1 = []\n",
    "    set2 = []\n",
    "    set3 = []\n",
    "    for id in list(data_set.keys()):\n",
    "        set1.append('__label__' + data_set[id]['tag_level_1'] + ' ' + fixText(data_set[id]['text']))\n",
    "        set2.append('__label__' + resetLabelLv2(data_set[id]['tag_level_2']) + ' ' + fixText(data_set[id]['text']))\n",
    "        set3.append('__label__' + resetLabelLv3(data_set[id]['tag_level_3']) + ' ' + fixText(data_set[id]['text']))\n",
    "    try:\n",
    "        os.mkdir(TEMP_DIR)\n",
    "    except:\n",
    "        pass\n",
    "    with open(TEMP_DIR + 'set1.txt', 'w') as f:\n",
    "        for l in set1:\n",
    "            f.write(l + '\\n')\n",
    "    with open(TEMP_DIR + 'set2.txt', 'w') as f:\n",
    "        for l in set2:\n",
    "            f.write(l + '\\n')\n",
    "    with open(TEMP_DIR + 'set3.txt', 'w') as f:\n",
    "        for l in set3:\n",
    "            f.write(l + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 22M words\n",
      "Number of words:  268542\n",
      "Number of labels: 88\n",
      "Progress: 100.0% words/sec/thread:   14021 lr:  0.000000 avg.loss:  0.258725 ETA:   0h 0m 0s 25.9% words/sec/thread:   14999 lr:  0.074088 avg.loss:  0.408735 ETA:   0h 3m36s 0.370440 ETA:   0h 3m 9s  0h 2m29s 75.5% words/sec/thread:   14191 lr:  0.024521 avg.loss:  0.289011 ETA:   0h 1m15s\n",
      "Read 22M words\n",
      "Number of words:  268542\n",
      "Number of labels: 482\n",
      "Progress:   4.3% words/sec/thread:    5894 lr:  0.095687 avg.loss:  2.434911 ETA:   0h11m51s"
     ]
    }
   ],
   "source": [
    "config = getConfig()\n",
    "readDataSet(config['data_path'] + config['data_set_name'])\n",
    "model_label1 = fasttext.train_supervised(\n",
    "    input = TEMP_DIR + 'set1.txt',\n",
    "    lr = config['lr'],\n",
    "    dim = config['hidden_dim'],\n",
    "    epoch = config['epoch']\n",
    ")\n",
    "model_label2 = fasttext.train_supervised(\n",
    "    input = TEMP_DIR + 'set2.txt',\n",
    "    lr = config['lr'],\n",
    "    dim = config['hidden_dim'],\n",
    "    epoch = config['epoch']\n",
    ")\n",
    "model_label3 = fasttext.train_supervised(\n",
    "    input = TEMP_DIR + 'set3.txt',\n",
    "    lr = config['lr'],\n",
    "    dim = config['hidden_dim'],\n",
    "    epoch = config['epoch']\n",
    ")\n",
    "\n",
    "try:\n",
    "    os.remove(TEMP_DIR + 'set1.txt')\n",
    "    os.remove(TEMP_DIR + 'set2.txt')\n",
    "    os.remove(TEMP_DIR + 'set3.txt')\n",
    "    os.removedirs(TEMP_DIR)  \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.1, epoch = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(config[\u001b[39m'\u001b[39m\u001b[39mdata_path\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest_set.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     content \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(f\u001b[39m.\u001b[39mread())\n\u001b[1;32m      4\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "with open(config['data_path'] + 'test_set.json', 'r') as f:\n",
    "    content = json.loads(f.read())\n",
    "\n",
    "total = 0\n",
    "true_tag1 = 0\n",
    "true_tag2 = 0\n",
    "true_tag3 = 0\n",
    "for id in content.keys():\n",
    "    total += 1\n",
    "    text = content[id]['text']\n",
    "    text = fixText(text)\n",
    "    tag1 = content[id]['tag_level_1']\n",
    "    tag2 = content[id]['tag_level_2']\n",
    "    tag3 = content[id]['tag_level_3']\n",
    "    predict1 = model_tag1.predict(text)[0][0]\n",
    "    predict2 = model_tag2.predict(text)[0][0]\n",
    "    predict3 = model_tag3.predict(text)[0][0]\n",
    "    if(predict1.replace('__label__', '') == tag1):\n",
    "        true_tag1 += 1\n",
    "    if(predict2.replace('__label__', '') == tag2):\n",
    "        true_tag2 += 1\n",
    "    if(predict3.replace('__label__', '') == tag3):\n",
    "        true_tag3 += 1\n",
    "print('tag level 1 accurate: {}% ({}/{})'.format(true_tag1 * 100 / total, true_tag1, total))\n",
    "print('tag level 2 accurate: {}% ({}/{})'.format(true_tag2 * 100 / total, true_tag2, total))\n",
    "print('tag level 3 accurate: {}% ({}/{})'.format(true_tag3 * 100 / total, true_tag3, total))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标签数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "451\n",
      "1171\n"
     ]
    }
   ],
   "source": [
    "print('tag 1 num: ', len(model_label1.labels))\n",
    "print('tag 2 num: ', len(model_label2.labels))\n",
    "print('tag 3 num: ', len(model_label3.labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasttext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40c1bd7acade6d7fff3a845369481287e9bc1b29cba7a3ea4cdbf523b7c26458"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
