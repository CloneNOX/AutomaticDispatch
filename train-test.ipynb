{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import os\n",
    "import json\n",
    "from utils import fixText\n",
    "\n",
    "TEMP_DIR = './tmp/'\n",
    "\n",
    "def getConfig():\n",
    "    config = {}\n",
    "    with open('./config.json', 'r') as f:\n",
    "        s = f.read()\n",
    "        config = json.loads(s)\n",
    "    return config\n",
    "\n",
    "# 读入数据集的json文件，处理成fasttext接口使用的\"文本__label__标签\"形式，以txt文件存储\n",
    "def readDataSet(path):\n",
    "    with open(path, 'r') as f:\n",
    "        s = f.read()\n",
    "        data_set = json.loads(s)\n",
    "    set1 = []\n",
    "    set2 = []\n",
    "    set3 = []\n",
    "    for id in list(data_set.keys()):\n",
    "        set1.append('__label__' + data_set[id]['tag_level_1'] + ' ' + fixText(data_set[id]['text']))\n",
    "        set2.append('__label__' + data_set[id]['tag_level_2'] + ' ' + fixText(data_set[id]['text']))\n",
    "        set3.append('__label__' + data_set[id]['tag_level_3'] + ' ' + fixText(data_set[id]['text']))\n",
    "    try:\n",
    "        os.mkdir(TEMP_DIR)\n",
    "    except:\n",
    "        pass\n",
    "    with open(TEMP_DIR + 'set1.txt', 'w') as f:\n",
    "        for l in set1:\n",
    "            f.write(l + '\\n')\n",
    "    with open(TEMP_DIR + 'set2.txt', 'w') as f:\n",
    "        for l in set2:\n",
    "            f.write(l + '\\n')\n",
    "    with open(TEMP_DIR + 'set3.txt', 'w') as f:\n",
    "        for l in set3:\n",
    "            f.write(l + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.676 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Read 16M words\n",
      "Number of words:  131502\n",
      "Number of labels: 87\n",
      "Progress: 100.0% words/sec/thread:   10797 lr:  0.000000 avg.loss:  0.218876 ETA:   0h 0m 0s 19.5% words/sec/thread:   10769 lr:  0.080514 avg.loss:  0.358122 ETA:   0h 8m14s36s words/sec/thread:   10856 lr:  0.061395 avg.loss:  0.298506 ETA:   0h 6m14s 62.6% words/sec/thread:   10674 lr:  0.037411 avg.loss:  0.262466 ETA:   0h 3m51s ETA:   0h 3m 3s 79.0% words/sec/thread:   10638 lr:  0.021007 avg.loss:  0.237648 ETA:   0h 2m10s\n",
      "Read 16M words\n",
      "Number of words:  131502\n",
      "Number of labels: 451\n",
      "Progress: 100.0% words/sec/thread:    4934 lr:  0.000000 avg.loss:  0.612728 ETA:   0h 0m 0s   3997 lr:  0.099726 avg.loss:  4.325171 ETA:   0h27m31s  2.6% words/sec/thread:    4170 lr:  0.097371 avg.loss:  2.178534 ETA:   0h25m45s  3.3% words/sec/thread:    4221 lr:  0.096745 avg.loss:  2.043698 ETA:   0h25m16s  3.4% words/sec/thread:    4228 lr:  0.096592 avg.loss:  2.011498 ETA:   0h25m11s  3.6% words/sec/thread:    4230 lr:  0.096418 avg.loss:  1.984710 ETA:   0h25m 8s 18.0% words/sec/thread:    4466 lr:  0.081965 avg.loss:  1.282590 ETA:   0h20m14s 23.7% words/sec/thread:    4465 lr:  0.076338 avg.loss:  1.129764 ETA:   0h18m51s 23.8% words/sec/thread:    4465 lr:  0.076228 avg.loss:  1.129974 ETA:   0h18m49s 31.4% words/sec/thread:    4484 lr:  0.068622 avg.loss:  1.006754 ETA:   0h16m52s 37.4% words/sec/thread:    4480 lr:  0.062612 avg.loss:  0.946519 ETA:   0h15m24s lr:  0.059284 avg.loss:  0.915182 ETA:   0h14m31s 55.9% words/sec/thread:    4671 lr:  0.044136 avg.loss:  0.810350 ETA:   0h10m25s 58.4% words/sec/thread:    4690 lr:  0.041596 avg.loss:  0.795918 ETA:   0h 9m46s 67.9% words/sec/thread:    4754 lr:  0.032082 avg.loss:  0.735126 ETA:   0h 7m26s 72.9% words/sec/thread:    4781 lr:  0.027133 avg.loss:  0.705797 ETA:   0h 6m15ss 75.8% words/sec/thread:    4798 lr:  0.024162 avg.loss:  0.690003 ETA:   0h 5m33s 78.0% words/sec/thread:    4811 lr:  0.021977 avg.loss:  0.681728 ETA:   0h 5m 2s 2m58s 87.5% words/sec/thread:    4862 lr:  0.012477 avg.loss:  0.652733 ETA:   0h 2m49s 98.5% words/sec/thread:    4926 lr:  0.001511 avg.loss:  0.616282 ETA:   0h 0m20s\n",
      "Read 16M words\n",
      "Number of words:  131515\n",
      "Number of labels: 1171\n",
      "Progress: 100.0% words/sec/thread:    3057 lr:  0.000000 avg.loss:  1.292126 ETA:   0h 0m 0s% words/sec/thread:    2714 lr:  0.098793 avg.loss:  6.372217 ETA:   0h40m 8s  2.0% words/sec/thread:    2872 lr:  0.097994 avg.loss:  5.507293 ETA:   0h37m38s  3.5% words/sec/thread:    2970 lr:  0.096454 avg.loss:  4.665099 ETA:   0h35m49s% words/sec/thread:    2978 lr:  0.096133 avg.loss:  4.463992 ETA:   0h35m36s  9.0% words/sec/thread:    3041 lr:  0.091005 avg.loss:  3.422137 ETA:   0h33m 0s 10.2% words/sec/thread:    3047 lr:  0.089765 avg.loss:  3.249606 ETA:   0h32m29s 12.3% words/sec/thread:    3057 lr:  0.087742 avg.loss:  3.038859 ETA:   0h31m39s 15.3% words/sec/thread:    3053 lr:  0.084701 avg.loss:  2.793765 ETA:   0h30m36s 17.0% words/sec/thread:    3035 lr:  0.082979 avg.loss:  2.679493 ETA:   0h30m 9s 20.8% words/sec/thread:    2999 lr:  0.079153 avg.loss:  2.493769 ETA:   0h29m 6s 0.077693 avg.loss:  2.428422 ETA:   0h28m37s lr:  0.074844 avg.loss:  2.332016 ETA:   0h27m43s 26.1% words/sec/thread:    2977 lr:  0.073886 avg.loss:  2.305242 ETA:   0h27m22s words/sec/thread:    2977 lr:  0.073655 avg.loss:  2.300827 ETA:   0h27m17s 0.047868 avg.loss:  1.804998 ETA:   0h17m30s 66.7% words/sec/thread:    3024 lr:  0.033255 avg.loss:  1.607204 ETA:   0h12m 7s 82.2% words/sec/thread:    3045 lr:  0.017804 avg.loss:  1.450627 ETA:   0h 6m26s 83.5% words/sec/thread:    3044 lr:  0.016510 avg.loss:  1.436895 ETA:   0h 5m58s\n"
     ]
    }
   ],
   "source": [
    "config = getConfig()\n",
    "readDataSet(config['data_path'] + config['data_set_path'])\n",
    "model_tag1 = fasttext.train_supervised(\n",
    "    input = TEMP_DIR + 'set1.txt',\n",
    "    lr = config['lr'],\n",
    "    dim = config['hidden_dim'],\n",
    "    epoch = config['epoch']\n",
    ")\n",
    "model_tag2 = fasttext.train_supervised(\n",
    "    input = TEMP_DIR + 'set2.txt',\n",
    "    lr = config['lr'],\n",
    "    dim = config['hidden_dim'],\n",
    "    epoch = config['epoch']\n",
    ")\n",
    "model_tag3 = fasttext.train_supervised(\n",
    "    input = TEMP_DIR + 'set3.txt',\n",
    "    lr = config['lr'],\n",
    "    dim = config['hidden_dim'],\n",
    "    epoch = config['epoch']\n",
    ")\n",
    "\n",
    "try:\n",
    "    os.remove(TEMP_DIR + 'set1.txt')\n",
    "    os.remove(TEMP_DIR + 'set2.txt')\n",
    "    os.remove(TEMP_DIR + 'set3.txt')\n",
    "    os.removedirs(TEMP_DIR)  \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.1, epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag level 1 accurate: 93.85076963214192% (35973/38330)\n",
      "tag level 2 accurate: 74.5995303939473% (28594/38330)\n",
      "tag level 3 accurate: 65.4056874510827% (25070/38330)\n"
     ]
    }
   ],
   "source": [
    "with open(config['data_path'] + 'test_set.json', 'r') as f:\n",
    "    content = json.loads(f.read())\n",
    "\n",
    "total = 0\n",
    "true_tag1 = 0\n",
    "true_tag2 = 0\n",
    "true_tag3 = 0\n",
    "for id in content.keys():\n",
    "    total += 1\n",
    "    text = content[id]['text']\n",
    "    text = fixText(text)\n",
    "    tag1 = content[id]['tag_level_1']\n",
    "    tag2 = content[id]['tag_level_2']\n",
    "    tag3 = content[id]['tag_level_3']\n",
    "    predict1 = model_tag1.predict(text)[0][0]\n",
    "    predict2 = model_tag2.predict(text)[0][0]\n",
    "    predict3 = model_tag3.predict(text)[0][0]\n",
    "    if(predict1.replace('__label__', '') == tag1):\n",
    "        true_tag1 += 1\n",
    "    if(predict2.replace('__label__', '') == tag2):\n",
    "        true_tag2 += 1\n",
    "    if(predict3.replace('__label__', '') == tag3):\n",
    "        true_tag3 += 1\n",
    "print('tag level 1 accurate: {}% ({}/{})'.format(true_tag1 * 100 / total, true_tag1, total))\n",
    "print('tag level 2 accurate: {}% ({}/{})'.format(true_tag2 * 100 / total, true_tag2, total))\n",
    "print('tag level 3 accurate: {}% ({}/{})'.format(true_tag3 * 100 / total, true_tag3, total))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.01 epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag level 1 accurate: 94.004696060527% (36032/38330)\n",
      "tag level 2 accurate: 63.04200365249152% (24164/38330)\n",
      "tag level 3 accurate: 44.29689538220715% (16979/38330)\n"
     ]
    }
   ],
   "source": [
    "with open(config['data_path'] + 'test_set.json', 'r') as f:\n",
    "    content = json.loads(f.read())\n",
    "\n",
    "total = 0\n",
    "true_tag1 = 0\n",
    "true_tag2 = 0\n",
    "true_tag3 = 0\n",
    "for id in content.keys():\n",
    "    total += 1\n",
    "    text = content[id]['text']\n",
    "    text = fixText(text)\n",
    "    tag1 = content[id]['tag_level_1']\n",
    "    tag2 = content[id]['tag_level_2']\n",
    "    tag3 = content[id]['tag_level_3']\n",
    "    predict1 = model_tag1.predict(text)[0][0]\n",
    "    predict2 = model_tag2.predict(text)[0][0]\n",
    "    predict3 = model_tag3.predict(text)[0][0]\n",
    "    if(predict1.replace('__label__', '') == tag1):\n",
    "        true_tag1 += 1\n",
    "    if(predict2.replace('__label__', '') == tag2):\n",
    "        true_tag2 += 1\n",
    "    if(predict3.replace('__label__', '') == tag3):\n",
    "        true_tag3 += 1\n",
    "print('tag level 1 accurate: {}% ({}/{})'.format(true_tag1 * 100 / total, true_tag1, total))\n",
    "print('tag level 2 accurate: {}% ({}/{})'.format(true_tag2 * 100 / total, true_tag2, total))\n",
    "print('tag level 3 accurate: {}% ({}/{})'.format(true_tag3 * 100 / total, true_tag3, total))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.001 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag level 1 accurate: 93.98121575789199%(36023/38330)\n",
      "tag level 2 accurate: 35.330028698147665%(13542/38330)\n",
      "tag level 3 accurate: 25.927471954082964%(9938/38330)\n"
     ]
    }
   ],
   "source": [
    "with open(config['data_path'] + 'test_set.json', 'r') as f:\n",
    "    content = json.loads(f.read())\n",
    "\n",
    "total = 0\n",
    "true_tag1 = 0\n",
    "true_tag2 = 0\n",
    "true_tag3 = 0\n",
    "for id in content.keys():\n",
    "    total += 1\n",
    "    text = content[id]['text']\n",
    "    text = fixText(text)\n",
    "    tag1 = content[id]['tag_level_1']\n",
    "    tag2 = content[id]['tag_level_2']\n",
    "    tag3 = content[id]['tag_level_3']\n",
    "    predict1 = model_tag1.predict(text)[0][0]\n",
    "    predict2 = model_tag2.predict(text)[0][0]\n",
    "    predict3 = model_tag3.predict(text)[0][0]\n",
    "    if(predict1.replace('__label__', '') == tag1):\n",
    "        true_tag1 += 1\n",
    "    if(predict2.replace('__label__', '') == tag2):\n",
    "        true_tag2 += 1\n",
    "    if(predict3.replace('__label__', '') == tag3):\n",
    "        true_tag3 += 1\n",
    "print('tag level 1 accurate: {}% ({}/{})'.format(true_tag1 * 100 / total, true_tag1, total))\n",
    "print('tag level 2 accurate: {}% ({}/{})'.format(true_tag2 * 100 / total, true_tag2, total))\n",
    "print('tag level 3 accurate: {}% ({}/{})'.format(true_tag3 * 100 / total, true_tag3, total))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标签数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "451\n",
      "1171\n"
     ]
    }
   ],
   "source": [
    "print('tag 1 num: ', len(model_tag1.labels))\n",
    "print('tag 2 num: ', len(model_tag2.labels))\n",
    "print('tag 3 num: ', len(model_tag3.labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasttext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40c1bd7acade6d7fff3a845369481287e9bc1b29cba7a3ea4cdbf523b7c26458"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
